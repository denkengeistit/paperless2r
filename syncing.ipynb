{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import asyncio\n",
    "import os\n",
    "from pypaperless import Paperless\n",
    "from r2r import R2RClient\n",
    "import requests\n",
    "from contextlib import asynccontextmanager\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def getTags(paperless):\n",
    "    tag_list = []\n",
    "    async for item in paperless.tags:\n",
    "        tag_data = item._data\n",
    "        #print(f\"Tag Data: {tag_data}\")  # Debug structure\n",
    "        try:\n",
    "            tag_id = tag_data['id']  # Get tag ID\n",
    "            tag_name = tag_data['name']\n",
    "            if tag_name == \"Personal\":\n",
    "                print(f\"Skipping tag '{tag_name}'.\")\n",
    "                continue# Get tag name\n",
    "            tag_list.append((tag_id, tag_name))\n",
    "        except KeyError as e:\n",
    "            print(f\"Missing key in tag data: {e}. Skipping tag.\")\n",
    "            continue\n",
    "    return tag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "async def getDocs(paperless,filters):\n",
    "    document_ids = []\n",
    "    async with paperless.documents.reduce(**filters) as filtered:\n",
    "        async for item in filtered:\n",
    "            try:\n",
    "                docid = item.id\n",
    "                document_ids.append(docid)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {docid}: {e}\")    \n",
    "    return document_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "async def fetch_tag_document_count(paperless, tag_id):\n",
    "    \"\"\"\n",
    "    Fetch the current number of documents for a specific tag in Paperless.\n",
    "    :param paperless: Initialized Paperless client.\n",
    "    :param tag_id: The ID of the tag to fetch document count for.\n",
    "    :return: The number of documents associated with the tag.\n",
    "    \"\"\"\n",
    "    filters = {\"tags__id\": tag_id}\n",
    "    document_ids = await getDocs(paperless, filters)\n",
    "    return len(document_ids)\n",
    "\n",
    "\n",
    "def fetch_collection_document_count(r2r_client, collection_id):\n",
    "    \"\"\"\n",
    "    Fetch the current number of documents in a specific R2R collection.\n",
    "    :param r2r_client: Initialized R2R client.\n",
    "    :param collection_id: The ID of the collection to fetch document count for.\n",
    "    :return: The number of documents in the collection.\n",
    "    \"\"\"\n",
    "    response = r2r_client.collections.retrieve(collection_id)\n",
    "    return response['results']['document_count']\n",
    "    \n",
    "async def process_documents_in_batches(document_ids, batch_size, paperless, r2r_client, collection_id):\n",
    "    # Use asyncio.gather to process batches concurrently\n",
    "    tasks = []\n",
    "    for i in range(0, len(document_ids), batch_size):\n",
    "      batch = document_ids[i:i + batch_size]\n",
    "      tasks.append(process_document_batch(batch, paperless, r2r_client, collection_id))\n",
    "    await asyncio.gather(*tasks)\n",
    "\n",
    "async def sync_tag(\n",
    "    paperless, r2r_client, tag_id, tag_name, r2r_collection_map, batch_size\n",
    "):\n",
    "    \"\"\"\n",
    "    Sync a single tag and its associated documents from Paperless to R2R.\n",
    "\n",
    "    Skips the tag if the document counts in Paperless and R2R match.\n",
    "    :param paperless: Initialized Paperless client.\n",
    "    :param r2r_client: Initialized R2R client.\n",
    "    :param tag_id: Paperless tag ID.\n",
    "    :param tag_name: Paperless tag name.\n",
    "    :param r2r_collection_map: A map of R2R collection names to IDs.\n",
    "    :param batch_size: The batch size for processing documents.\n",
    "    \"\"\"\n",
    "    print(f\"Processing tag '{tag_name}'...\")\n",
    "\n",
    "    # Check if the tag already exists in the R2R collections\n",
    "    collection_id = r2r_collection_map.get(tag_name)\n",
    "    if not collection_id:\n",
    "        print(f\"Collection '{tag_name}' not found in R2R. Creating...\")\n",
    "        create_result = r2r_client.collections.create(name=tag_name)\n",
    "        collection_id = create_result[\"id\"]\n",
    "        r2r_collection_map[tag_name] = collection_id  # Update the collection map\n",
    "\n",
    "    # Fetch the document counts for this tag (from Paperless and R2R)\n",
    "    paperless_doc_count = await fetch_tag_document_count(paperless, tag_id)\n",
    "    r2r_doc_count = fetch_collection_document_count(r2r_client, collection_id)\n",
    "\n",
    "    # Compare document counts\n",
    "    if paperless_doc_count <= r2r_doc_count:\n",
    "        print(f\"Skipping tag '{tag_name}': Document counts match ({paperless_doc_count}).\")\n",
    "        return  # Skip this tag if the counts match\n",
    "\n",
    "    print(\n",
    "        f\"Document counts differ for tag '{tag_name}': \"\n",
    "        f\"Paperless={paperless_doc_count}, R2R={r2r_doc_count}. Processing...\"\n",
    "    )\n",
    "    filters = {\"tags__id\": tag_id}\n",
    "    document_ids = await getDocs(paperless, filters)\n",
    "    await process_documents_in_batches(\n",
    "        document_ids, batch_size, paperless, r2r_client, collection_id\n",
    "    )\n",
    "\n",
    "\n",
    "async def process_document_batch(batch, paperless, r2r_client, collection_id, custom_field_name='document_id'):\n",
    "    \"\"\"\n",
    "    Process a batch of documents: either ingest them into R2R or associate existing documents\n",
    "    with the correct collection.\n",
    "\n",
    "    :param batch: List of Paperless document IDs to process.\n",
    "    :param paperless: Initialized Paperless client.\n",
    "    :param r2r_client: Initialized R2R client.\n",
    "    :param collection_id: The collection ID in R2R to add documents to.\n",
    "    :param custom_field_name: The name of the custom field storing the R2R document ID.\n",
    "    \"\"\"\n",
    "    for docid in batch:\n",
    "        # Check for existing R2RDocumentID in Paperless\n",
    "        existing_r2r_id = await get_r2r_document_id_from_paperless(paperless, docid, custom_field_name)\n",
    "        \n",
    "        if existing_r2r_id:\n",
    "            print(f\"Document {docid} already has R2R ID {existing_r2r_id}.\")\n",
    "            # Add the existing document to the collection in R2R\n",
    "            try:\n",
    "                await docToCollect(existing_r2r_id, collection_id, r2r_client)\n",
    "            except Exception as e:\n",
    "                print(f\"Error adding document {existing_r2r_id} to collection {collection_id}: {e}\")\n",
    "            continue  # Skip ingestion if the document already exists in R2R\n",
    "        \n",
    "        # Try to fetch the document file path\n",
    "        file_path = await getPath(paperless, docid)\n",
    "        if not file_path:\n",
    "            print(f\"Skipping document {docid}: File path not found.\")\n",
    "            continue\n",
    "\n",
    "        # Ingest the document into R2R\n",
    "        try:\n",
    "            document_id = await ingest(docid, file_path, r2r_client, collection_id)\n",
    "            print(f\"Document {docid} successfully ingested as {document_id}.\")\n",
    "            \n",
    "            # Add the document to the custom field in Paperless\n",
    "            custom_field_name='document_id'\n",
    "            await update_custom_field(paperless, docid, custom_field_name, document_id)\n",
    "            \n",
    "            # Add the document to the collection in R2R\n",
    "            await docToCollect(document_id, collection_id, r2r_client)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing document {docid}: {e}\")\n",
    "# Get full file path of a document (optimized)\n",
    "async def getPath(paperless, docid):\n",
    "    doc_string = 'ScanToPDF'\n",
    "    document = await paperless.documents(docid)\n",
    "    created_date = document.created_date\n",
    "    date_string = created_date.strftime('%Y')\n",
    "    doc_title = document.title\n",
    "    search_paths = [\n",
    "        f'/home/admin/Paperless/media/documents/archive/Private/{doc_string}/{date_string}/{doc_title}.pdf',\n",
    "        f'/home/admin/Paperless/media/documents/originals/Private/{doc_string}/{date_string}/{doc_title}.pdf'\n",
    "    ]\n",
    "    for path in search_paths:\n",
    "        if os.path.exists(path):\n",
    "            return path\n",
    "    print(f\"File not found for document {docid}\")\n",
    "    return None\n",
    "    \n",
    "async def ingest(docid, file_path, client, collectid):\n",
    "    \"\"\"\n",
    "    Ingest a single document into R2R and return the document ID.\n",
    "    Raises an exception if ingestion fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Attempt to create the document in R2R\n",
    "        response = client.documents.create(\n",
    "            file_path=file_path,\n",
    "            metadata={\"PaperlessID\": docid},\n",
    "            id=None\n",
    "        )\n",
    "        document_id = response['results'][0]['document_id']\n",
    "        return document_id\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error during ingestion: {e}\")\n",
    "        \n",
    "def extract_document_id_from_error(error_message):\n",
    "    \"\"\"\n",
    "    Extracts the document ID from error messages indicating a document already exists.\n",
    "    \"\"\"\n",
    "    import re\n",
    "\n",
    "    # Use regex to extract UUID from the error message\n",
    "    match = re.search(r\"/documents/([a-f0-9\\-]{36})\", error_message)\n",
    "    if match:\n",
    "        return match.group(1)  # Return the first matching group (the document ID)\n",
    "    return None\n",
    "    \n",
    "async def docToCollect(document_id, collection_id, r2r_client):\n",
    "    \"\"\"\n",
    "    Assign a document to a collection in R2R.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Add the document to the specified collection\n",
    "        assign_doc_result = r2r_client.collections.add_document(collection_id, document_id)\n",
    "        print(f\"Document {document_id} successfully added to collection {collection_id}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error assigning document {document_id} to collection {collection_id}: {e}\")\n",
    "\n",
    "async def sync_paperless_to_r2r(paperless, r2r_client_url, batch_size=10):\n",
    "    \"\"\"\n",
    "    Sync all Paperless tags and documents with R2R collections in real-time.\n",
    "    :param paperless: Initialized Paperless client.\n",
    "    :param r2r_client_url: The R2R API base URL.\n",
    "    :param batch_size: The batch size for processing documents.\n",
    "    \"\"\"\n",
    "    # await paperless.initialize()\n",
    "\n",
    "    try:\n",
    "        # Initialize R2R client\n",
    "        await paperless.initialize()\n",
    "        r2r_client = R2RClient(r2r_client_url)\n",
    "\n",
    "        # Fetch Paperless tags\n",
    "        paperless_tags = await getTags(paperless)\n",
    "\n",
    "        # Fetch R2R collections\n",
    "        r2r_collections = r2r_client.collections.list(offset=0, limit=1000)[\"results\"]\n",
    "        r2r_collection_map = {collection[\"name\"]: collection[\"id\"] for collection in r2r_collections}\n",
    "\n",
    "        # Process tags concurrently\n",
    "        await asyncio.gather(\n",
    "            *(\n",
    "                sync_tag(\n",
    "                    paperless, r2r_client, tag_id, tag_name, r2r_collection_map, batch_size\n",
    "                )\n",
    "                for tag_id, tag_name in paperless_tags\n",
    "            )\n",
    "        )\n",
    "        await paperless.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Critical error in sync_paperless_to_r2r: {e}\")\n",
    "    # finally:\n",
    "    #     await paperless.close()\n",
    "\n",
    "\n",
    "\n",
    "# async def get_r2r_document_id_from_paperless(paperless, docid, custom_field_name):\n",
    "#     \"\"\"\n",
    "#     Fetch the `R2RDocumentID` custom field's value for a Paperless document.\n",
    "    \n",
    "#     :param paperless: Initialized Paperless client.\n",
    "#     :param docid: Document ID in Paperless.\n",
    "#     :param custom_field_name: The name of the custom field to check.\n",
    "#     :return: The value of the custom field (if it exists) or None.\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         document = await paperless.documents(docid)\n",
    "#         custom_fields = document.custom_fields\n",
    "#         for field in custom_fields:\n",
    "#             if field[\"name\"] == custom_field_name:\n",
    "#                 return field[\"value\"]\n",
    "#     except KeyError:\n",
    "#         print(f\"Custom field '{custom_field_name}' not found for document {docid}.\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error fetching custom field for document {docid}: {e}\")\n",
    "    \n",
    "#     return None\n",
    "async def get_r2r_document_id_from_paperless(paperless, docid, custom_field_name):\n",
    "    try:\n",
    "        # Fetch the document by docid\n",
    "        document = await paperless.documents(docid)\n",
    "        \n",
    "        # Iterate through custom fields to find the one with the specified name\n",
    "        for custom_field in document.custom_fields:\n",
    "            if custom_field.field == custom_field_name:\n",
    "                return custom_field.value\n",
    "        \n",
    "        # If the custom field is not found, return None\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching custom field for document {docid}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def update_custom_field(paperless, docid, custom_field_name, custom_field_value):\n",
    "    try:\n",
    "        # Fetch the document by docid\n",
    "        document = await paperless.documents(docid)\n",
    "        \n",
    "        # Retrieve the custom field definitions to get the field ID\n",
    "        custom_fields_definitions = await paperless.custom_fields.list()\n",
    "        field_id = None\n",
    "        for field_def in custom_fields_definitions:\n",
    "            if field_def.name == custom_field_name:\n",
    "                field_id = field_def.id\n",
    "                break\n",
    "        if field_id is None:\n",
    "            print(f\"Custom field '{custom_field_name}' not found.\")\n",
    "            return\n",
    "        \n",
    "        # Update existing custom field or add a new one\n",
    "        custom_field_updated = False\n",
    "        for custom_field in document.custom_fields:\n",
    "            if custom_field.field == field_id:\n",
    "                custom_field.value = str(custom_field_value)\n",
    "                custom_field_updated = True\n",
    "                break\n",
    "        if not custom_field_updated:\n",
    "            # Append the new custom field\n",
    "            document.custom_fields.append({\n",
    "                \"field\": field_id,\n",
    "                \"value\": str(custom_field_value)\n",
    "            })\n",
    "        \n",
    "        # Save the changes\n",
    "        success = await document.update()\n",
    "        \n",
    "        if success:\n",
    "            print(f\"Successfully updated document {docid} with custom field '{custom_field_name}' = {custom_field_value}\")\n",
    "        else:\n",
    "            print(f\"Failed to update document {docid}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error updating custom field for document {docid}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-18 13:41:17,748 - INFO - pypaperless[paperless.escaffinity.com] - Initialized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping tag 'Personal'.\n",
      "Processing tag 'Administrative'...\n",
      "Processing tag 'Agile\\Agility'...\n",
      "Processing tag 'Ben Franklin'...\n",
      "Processing tag 'CAD/CAM'...\n",
      "Processing tag 'CAM\\CIM Labs'...\n",
      "Processing tag 'CELDi'...\n",
      "Processing tag 'Collaboratory'...\n",
      "Processing tag 'Coursework'...\n",
      "Processing tag 'Focus Hope'...\n",
      "Processing tag 'Iacocca Institute'...\n",
      "Processing tag 'IBM Research Program'...\n",
      "Processing tag 'ILR'...\n",
      "Processing tag 'INFORMS'...\n",
      "Processing tag 'Interdisciplinary Programs'...\n",
      "Processing tag 'Leadership'...\n",
      "Processing tag 'Lehigh EXPOs'...\n",
      "Processing tag 'Manufacturing'...\n",
      "Processing tag 'NSLS'...\n",
      "Processing tag 'PMFI'...\n",
      "Processing tag 'UEDA'...\n",
      "Skipping tag 'Administrative': Document counts match (1).\n",
      "Skipping tag 'Interdisciplinary Programs': Document counts match (0).\n",
      "Skipping tag 'UEDA': Document counts match (0).\n",
      "Skipping tag 'PMFI': Document counts match (0).\n",
      "Document counts differ for tag 'NSLS': Paperless=3, R2R=2. Processing...\n",
      "Skipping tag 'INFORMS': Document counts match (8).\n",
      "Document counts differ for tag 'Collaboratory': Paperless=11, R2R=6. Processing...\n",
      "Skipping tag 'ILR': Document counts match (6).\n",
      "Skipping tag 'Lehigh EXPOs': Document counts match (16).\n",
      "Error processing document 3850: Error during ingestion: An error '500: Error during ingestion: Document e8fc4b2a-07b2-5b9b-bd1b-584b1205ebcd already exists. Submit a DELETE request to `/documents/e8fc4b2a-07b2-5b9b-bd1b-584b1205ebcd` to delete this document and allow for re-ingestion.' occurred during create_document\n",
      "Document counts differ for tag 'CELDi': Paperless=35, R2R=11. Processing...\n",
      "Error processing document 5692: Error during ingestion: An error '500: Error during ingestion: Document 4eee730d-576c-551c-b2d2-9d193b97e44c already exists. Submit a DELETE request to `/documents/4eee730d-576c-551c-b2d2-9d193b97e44c` to delete this document and allow for re-ingestion.' occurred during create_document\n",
      "Error processing document 3581: Error during ingestion: An error '500: Error during ingestion: Document 999ece5d-ff0b-5e19-802a-26ac8cc8e673 already exists. Submit a DELETE request to `/documents/999ece5d-ff0b-5e19-802a-26ac8cc8e673` to delete this document and allow for re-ingestion.' occurred during create_document\n",
      "Error processing document 1455: Error during ingestion: An error '500: Error during ingestion: Document c8ad713e-1269-593d-ad67-ff7c3982f3b3 already exists. Submit a DELETE request to `/documents/c8ad713e-1269-593d-ad67-ff7c3982f3b3` to delete this document and allow for re-ingestion.' occurred during create_document\n",
      "Error fetching custom field for document 9177: Connection timeout to host https://paperless.escaffinity.com/api/documents/9177/\n",
      "Error processing document 4954: Error during ingestion: An error '500: Error during ingestion: Document 66a17495-51c0-549c-852e-802eba88b993 already exists. Submit a DELETE request to `/documents/66a17495-51c0-549c-852e-802eba88b993` to delete this document and allow for re-ingestion.' occurred during create_document\n",
      "Error processing document 9177: Error during ingestion: An error '500: Error during ingestion: Document 413c2877-c4e2-5c09-9782-770a79aae6e3 already exists. Submit a DELETE request to `/documents/413c2877-c4e2-5c09-9782-770a79aae6e3` to delete this document and allow for re-ingestion.' occurred during create_document\n",
      "Error processing document 1350: Error during ingestion: An error '500: Error during ingestion: Document a64df19e-9c00-5cab-8f2f-f4e7df2bf3db already exists. Submit a DELETE request to `/documents/a64df19e-9c00-5cab-8f2f-f4e7df2bf3db` to delete this document and allow for re-ingestion.' occurred during create_document\n",
      "Document counts differ for tag 'Coursework': Paperless=118, R2R=16. Processing...\n",
      "Document counts differ for tag 'Iacocca Institute': Paperless=182, R2R=9. Processing...\n",
      "Error processing document 5356: Error during ingestion: An error '500: Error during ingestion: Document 8034c02a-f112-59af-a70c-38cead8a8b81 already exists. Submit a DELETE request to `/documents/8034c02a-f112-59af-a70c-38cead8a8b81` to delete this document and allow for re-ingestion.' occurred during create_document\n",
      "Error processing document 5126: Error during ingestion: An error '500: Error during ingestion: Document a098d259-6ee0-514f-b187-c6ccbcfc0e94 already exists. Submit a DELETE request to `/documents/a098d259-6ee0-514f-b187-c6ccbcfc0e94` to delete this document and allow for re-ingestion.' occurred during create_document\n",
      "Skipping tag 'Agile\\Agility': Document counts match (109).\n",
      "Document counts differ for tag 'Focus Hope': Paperless=189, R2R=3. Processing...\n",
      "Error processing document 1351: Error during ingestion: An error '500: Error during ingestion: Document f8243e23-f0cd-56da-b420-f6831a670b9e already exists. Submit a DELETE request to `/documents/f8243e23-f0cd-56da-b420-f6831a670b9e` to delete this document and allow for re-ingestion.' occurred during create_document\n",
      "Document counts differ for tag 'Manufacturing': Paperless=189, R2R=0. Processing...\n",
      "Error processing document 5357: Error during ingestion: An error '500: Error during ingestion: Document 609eeebf-3a0c-5287-88a0-fc14f7b79a72 already exists. Submit a DELETE request to `/documents/609eeebf-3a0c-5287-88a0-fc14f7b79a72` to delete this document and allow for re-ingestion.' occurred during create_document\n",
      "Error processing document 1454: Error during ingestion: An error '500: Error during ingestion: Document 279a2987-44bc-5b94-b91a-bc3615d428a1 already exists. Submit a DELETE request to `/documents/279a2987-44bc-5b94-b91a-bc3615d428a1` to delete this document and allow for re-ingestion.' occurred during create_document\n",
      "Document counts differ for tag 'IBM Research Program': Paperless=427, R2R=0. Processing...\n",
      "Error processing document 1342: Error during ingestion: An error '500: Error during ingestion: Document 789f3bc0-3368-5d3e-bb50-5206000e1a93 already exists. Submit a DELETE request to `/documents/789f3bc0-3368-5d3e-bb50-5206000e1a93` to delete this document and allow for re-ingestion.' occurred during create_document\n",
      "Error processing document 5360: Error during ingestion: An error '500: Error during ingestion: Document 7da5cbb4-b747-522c-952b-a23c4c048cf5 already exists. Submit a DELETE request to `/documents/7da5cbb4-b747-522c-952b-a23c4c048cf5` to delete this document and allow for re-ingestion.' occurred during create_document\n",
      "Error processing document 5952: Error during ingestion: An error '500: Error during ingestion: Document 5c75b580-647f-5cfe-bb5a-5a29e65303ef already exists. Submit a DELETE request to `/documents/5c75b580-647f-5cfe-bb5a-5a29e65303ef` to delete this document and allow for re-ingestion.' occurred during create_document\n",
      "Document counts differ for tag 'Leadership': Paperless=433, R2R=0. Processing...\n",
      "Error processing document 1355: Error during ingestion: An error '500: Error during ingestion: Document c08e9495-1d74-514a-b614-76d6790ace9f already exists. Submit a DELETE request to `/documents/c08e9495-1d74-514a-b614-76d6790ace9f` to delete this document and allow for re-ingestion.' occurred during create_document\n",
      "Error processing document 695: Error during ingestion: An error '500: Error during ingestion: Document 63ead5ba-55e5-5088-8e4e-1fb9b2d6fd7c already exists. Submit a DELETE request to `/documents/63ead5ba-55e5-5088-8e4e-1fb9b2d6fd7c` to delete this document and allow for re-ingestion.' occurred during create_document\n",
      "Error processing document 3842: Error during ingestion: An error '500: Error during ingestion: Document 81fa1c73-d7be-597d-ba0c-b47cee6448fd already exists. Submit a DELETE request to `/documents/81fa1c73-d7be-597d-ba0c-b47cee6448fd` to delete this document and allow for re-ingestion.' occurred during create_document\n",
      "Document counts differ for tag 'Ben Franklin': Paperless=864, R2R=5. Processing...\n",
      "Error processing document 1362: Error during ingestion: An error '500: Error during ingestion: Document c0627690-755f-5012-bc26-1716ca9a499a already exists. Submit a DELETE request to `/documents/c0627690-755f-5012-bc26-1716ca9a499a` to delete this document and allow for re-ingestion.' occurred during create_document\n",
      "Error processing document 583: Error during ingestion: An error '500: Error during ingestion: Document 19404f31-1b82-5c7b-be49-7c24defac5e6 already exists. Submit a DELETE request to `/documents/19404f31-1b82-5c7b-be49-7c24defac5e6` to delete this document and allow for re-ingestion.' occurred during create_document\n",
      "Error processing document 865: Error during ingestion: 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Entry point\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 16\u001b[0m     \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/r2r/lib/python3.11/site-packages/nest_asyncio.py:35\u001b[0m, in \u001b[0;36m_patch_asyncio.<locals>.run\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     33\u001b[0m task\u001b[38;5;241m.\u001b[39mcancel()\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m suppress(asyncio\u001b[38;5;241m.\u001b[39mCancelledError):\n\u001b[0;32m---> 35\u001b[0m     \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/r2r/lib/python3.11/site-packages/nest_asyncio.py:92\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     90\u001b[0m     f\u001b[38;5;241m.\u001b[39m_log_destroy_pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping:\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/r2r/lib/python3.11/site-packages/nest_asyncio.py:133\u001b[0m, in \u001b[0;36m_patch_loop.<locals>._run_once\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m curr_task \u001b[38;5;241m=\u001b[39m curr_tasks\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 133\u001b[0m     \u001b[43mhandle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;66;03m# restore the current task\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m curr_task \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.11/asyncio/events.py:80\u001b[0m, in \u001b[0;36mHandle._run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 80\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mSystemExit\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m):\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.11/asyncio/tasks.py:342\u001b[0m, in \u001b[0;36mTask.__wakeup\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    339\u001b[0m     future\u001b[38;5;241m.\u001b[39mresult()\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[0;32m--> 342\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;66;03m# Don't pass the value of `future.result()` explicitly,\u001b[39;00m\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;66;03m# as `Future.__iter__` and `Future.__await__` don't need it.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;66;03m# instead of `__next__()`, which is slower for futures\u001b[39;00m\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;66;03m# that return non-generator iterators from their `__iter__`.\u001b[39;00m\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__step()\n",
      "File \u001b[0;32m/usr/lib/python3.11/asyncio/tasks.py:269\u001b[0m, in \u001b[0;36mTask.__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    267\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 269\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_must_cancel:\n\u001b[1;32m    272\u001b[0m         \u001b[38;5;66;03m# Task is cancelled right before coro stops.\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[40], line 98\u001b[0m, in \u001b[0;36msync_tag\u001b[0;34m(paperless, r2r_client, tag_id, tag_name, r2r_collection_map, batch_size)\u001b[0m\n\u001b[1;32m     96\u001b[0m filters \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags__id\u001b[39m\u001b[38;5;124m\"\u001b[39m: tag_id}\n\u001b[1;32m     97\u001b[0m document_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m getDocs(paperless, filters)\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m process_documents_in_batches(\n\u001b[1;32m     99\u001b[0m     document_ids, batch_size, paperless, r2r_client, collection_id\n\u001b[1;32m    100\u001b[0m )\n",
      "Cell \u001b[0;32mIn[40], line 57\u001b[0m, in \u001b[0;36mprocess_documents_in_batches\u001b[0;34m(document_ids, batch_size, paperless, r2r_client, collection_id)\u001b[0m\n\u001b[1;32m     55\u001b[0m   batch \u001b[38;5;241m=\u001b[39m document_ids[i:i \u001b[38;5;241m+\u001b[39m batch_size]\n\u001b[1;32m     56\u001b[0m   tasks\u001b[38;5;241m.\u001b[39mappend(process_document_batch(batch, paperless, r2r_client, collection_id))\n\u001b[0;32m---> 57\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39mtasks)\n",
      "File \u001b[0;32m/usr/lib/python3.11/asyncio/tasks.py:339\u001b[0m, in \u001b[0;36mTask.__wakeup\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 339\u001b[0m         \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    341\u001b[0m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[1;32m    342\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__step(exc)\n",
      "File \u001b[0;32m~/r2r/lib/python3.11/site-packages/nest_asyncio.py:30\u001b[0m, in \u001b[0;36m_patch_asyncio.<locals>.run\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     28\u001b[0m task \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(main)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task\u001b[38;5;241m.\u001b[39mdone():\n",
      "File \u001b[0;32m~/r2r/lib/python3.11/site-packages/nest_asyncio.py:92\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     90\u001b[0m     f\u001b[38;5;241m.\u001b[39m_log_destroy_pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping:\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/r2r/lib/python3.11/site-packages/nest_asyncio.py:133\u001b[0m, in \u001b[0;36m_patch_loop.<locals>._run_once\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m curr_task \u001b[38;5;241m=\u001b[39m curr_tasks\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 133\u001b[0m     \u001b[43mhandle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;66;03m# restore the current task\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m curr_task \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.11/asyncio/events.py:80\u001b[0m, in \u001b[0;36mHandle._run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 80\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mSystemExit\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m):\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.11/asyncio/tasks.py:350\u001b[0m, in \u001b[0;36mTask.__wakeup\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__step(exc)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;66;03m# Don't pass the value of `future.result()` explicitly,\u001b[39;00m\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;66;03m# as `Future.__iter__` and `Future.__await__` don't need it.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;66;03m# instead of `__next__()`, which is slower for futures\u001b[39;00m\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;66;03m# that return non-generator iterators from their `__iter__`.\u001b[39;00m\n\u001b[0;32m--> 350\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.11/asyncio/tasks.py:267\u001b[0m, in \u001b[0;36mTask.__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    265\u001b[0m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[1;32m    266\u001b[0m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    269\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n",
      "Cell \u001b[0;32mIn[40], line 135\u001b[0m, in \u001b[0;36mprocess_document_batch\u001b[0;34m(batch, paperless, r2r_client, collection_id, custom_field_name)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# Ingest the document into R2R\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     document_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m ingest(docid, file_path, r2r_client, collection_id)\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDocument \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdocid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m successfully ingested as \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdocument_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;66;03m# Add the document to the custom field in Paperless\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[40], line 170\u001b[0m, in \u001b[0;36mingest\u001b[0;34m(docid, file_path, client, collectid)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03mIngest a single document into R2R and return the document ID.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;124;03mRaises an exception if ingestion fails.\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# Attempt to create the document in R2R\u001b[39;00m\n\u001b[0;32m--> 170\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPaperlessID\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocid\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m     document_id \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocument_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m document_id\n",
      "File \u001b[0;32m~/r2r/lib/python3.11/site-packages/sdk/sync_client.py:103\u001b[0m, in \u001b[0;36mR2RClient._make_sync_method.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(async_method)\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43masync_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/r2r/lib/python3.11/site-packages/nest_asyncio.py:92\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     90\u001b[0m     f\u001b[38;5;241m.\u001b[39m_log_destroy_pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping:\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/r2r/lib/python3.11/site-packages/nest_asyncio.py:115\u001b[0m, in \u001b[0;36m_patch_loop.<locals>._run_once\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m     heappop(scheduled)\n\u001b[1;32m    110\u001b[0m timeout \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ready \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mmax\u001b[39m(\n\u001b[1;32m    113\u001b[0m         scheduled[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_when \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime(), \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m86400\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m scheduled\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 115\u001b[0m event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_events(event_list)\n\u001b[1;32m    118\u001b[0m end_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clock_resolution\n",
      "File \u001b[0;32m/usr/lib/python3.11/selectors.py:468\u001b[0m, in \u001b[0;36mEpollSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    466\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 468\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selector\u001b[38;5;241m.\u001b[39mpoll(timeout, max_ev)\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Main program execution\n",
    "async def run():\n",
    "    paperless_url = \"https://paperless.escaffinity.com\"\n",
    "    paperless_api_key = \"0dad9947edf3a041e4e847160619213d908e3310\"\n",
    "    r2r_url = \"https://r2r.escaffinity.com\"\n",
    "    paperless = Paperless(paperless_url, paperless_api_key)\n",
    "    #await paperless.initialize()\n",
    "    # try:\n",
    "    await sync_paperless_to_r2r(paperless, r2r_url, batch_size=20)\n",
    "    # finally:\n",
    "    #     await paperless.close()\n",
    "\n",
    "nest_asyncio.apply()\n",
    "# Entry point\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(run())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-18 13:53:58,655 - INFO - pypaperless[paperless.escaffinity.com] - Initialized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching all documents from R2R...\n",
      "Updating Paperless document 2755 with R2R document ID 81f2e520-faae-5665-b0ad-6f0b9377f77f...\n",
      "Error updating custom field for document 2755: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 865 with R2R document ID dcca8c33-69fc-5713-89e8-d50643af85bf...\n",
      "Error updating custom field for document 865: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 866 with R2R document ID a2e17db8-5c07-521c-86f5-32a69374b814...\n",
      "Error updating custom field for document 866: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 5344 with R2R document ID f9870517-2505-5c0e-9267-c2658a3a256f...\n",
      "Error updating custom field for document 5344: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 5159 with R2R document ID 5df7ff9b-8e0c-5eaa-af63-4a56249eea99...\n",
      "Error updating custom field for document 5159: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 7184 with R2R document ID 543d4ca3-374c-5a6e-8a2b-30677c987800...\n",
      "Error updating custom field for document 7184: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 5469 with R2R document ID 25f576a9-b210-5e66-8b2a-620455834fc9...\n",
      "Error updating custom field for document 5469: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 7228 with R2R document ID 9399702a-3039-5f77-8762-7d6093843d68...\n",
      "Error updating custom field for document 7228: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 5432 with R2R document ID c832ba9f-8633-5a03-b3cf-2535e4143978...\n",
      "Error updating custom field for document 5432: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 5475 with R2R document ID 90ff6a21-dd49-51c4-a970-3ea692aa435f...\n",
      "Error updating custom field for document 5475: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 7670 with R2R document ID 35a4ffe4-0598-58df-9b3e-1dcc9b77d5c6...\n",
      "Error updating custom field for document 7670: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 8946 with R2R document ID 4108fb08-66d8-51c7-9c79-87182402fef2...\n",
      "Error updating custom field for document 8946: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 7284 with R2R document ID ebc2233a-a1ac-50e8-aff3-4fba21903cb1...\n",
      "Error updating custom field for document 7284: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 3596 with R2R document ID 5e80b5e6-9301-5239-b81b-ac8edd4be185...\n",
      "Error updating custom field for document 3596: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 8815 with R2R document ID a391a3a3-7e12-55f0-9594-23af999076ee...\n",
      "Error updating custom field for document 8815: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 5426 with R2R document ID 810bf46a-93d1-530d-8eda-864de4cee75d...\n",
      "Error updating custom field for document 5426: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 7347 with R2R document ID f8f6ba64-8ffc-5b19-9de1-2690d89efc0b...\n",
      "Error updating custom field for document 7347: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 7753 with R2R document ID 319007f3-dd23-5a75-a02a-6310c5806c96...\n",
      "Error updating custom field for document 7753: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 5522 with R2R document ID 825f2ee4-084e-5d21-b122-ff9b0e7d505c...\n",
      "Error updating custom field for document 5522: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 5399 with R2R document ID cbb61301-3d8b-5c2d-b96d-df1e7fe1bdc5...\n",
      "Error updating custom field for document 5399: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 7485 with R2R document ID 93e2b03d-6f6d-5ea2-a050-9b579623cf6b...\n",
      "Error updating custom field for document 7485: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 7309 with R2R document ID 816e31b3-a255-5013-9e75-da473fc12f51...\n",
      "Error updating custom field for document 7309: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 8609 with R2R document ID 0b26a20a-185d-548f-a007-cba971ed2958...\n",
      "Error updating custom field for document 8609: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 7586 with R2R document ID 7eb4e3f1-e4ec-5228-bc4d-b04a4547aceb...\n",
      "Error updating custom field for document 7586: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 7312 with R2R document ID 1082b2fe-380e-5e1f-bb11-655e8a4ea301...\n",
      "Error updating custom field for document 7312: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 5265 with R2R document ID adc274a4-6456-52cc-97ef-94bfbe4df249...\n",
      "Error updating custom field for document 5265: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 7405 with R2R document ID 0ae0e44d-c892-5765-945e-e1b494e6bbab...\n",
      "Error updating custom field for document 7405: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 7424 with R2R document ID feb8e987-4de6-5730-a420-4d43dd1f59b6...\n",
      "Error updating custom field for document 7424: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 7585 with R2R document ID a2cf88fa-5de4-58e6-b275-674adc20da8d...\n",
      "Error updating custom field for document 7585: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 7295 with R2R document ID d18bee78-df67-5171-9ed6-68814699ba03...\n",
      "Error updating custom field for document 7295: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 5391 with R2R document ID 32bdcd15-cbf3-579d-8ef5-7a9b87f64e12...\n",
      "Error updating custom field for document 5391: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 5217 with R2R document ID 9235ed01-6c85-5692-8ee8-03f99791d59e...\n",
      "Error updating custom field for document 5217: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 5545 with R2R document ID 7b225d71-afac-5618-96c9-32f992e2092b...\n",
      "Error updating custom field for document 5545: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 7754 with R2R document ID 80fe52e2-2c4e-5131-8edd-f11fcc6b2030...\n",
      "Error updating custom field for document 7754: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 5544 with R2R document ID 25a387fa-3ed6-53fe-8407-e77dfacd03ac...\n",
      "Error updating custom field for document 5544: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 5245 with R2R document ID 19b2f9b0-81ba-52fb-9573-ec2e30244ef3...\n",
      "Error updating custom field for document 5245: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 5436 with R2R document ID 7f5a041b-8e2a-5f08-85ec-2034c7b2255d...\n",
      "Error updating custom field for document 5436: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 7740 with R2R document ID 47fc625b-8f43-57e6-a48f-691eeb55720f...\n",
      "Error updating custom field for document 7740: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 7384 with R2R document ID fefc34cf-353b-5a68-a753-b9fc133bbcc7...\n",
      "Error updating custom field for document 7384: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 8610 with R2R document ID afc0cc6e-40b1-53b6-9e0a-087eaa96fa9c...\n",
      "Error updating custom field for document 8610: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 7476 with R2R document ID c9240165-9bb4-5ee9-993d-6b5fc424efa9...\n",
      "Error updating custom field for document 7476: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 7258 with R2R document ID fa39f6b3-7169-575a-ac83-b60696e40c35...\n",
      "Error updating custom field for document 7258: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 7293 with R2R document ID 5c515f72-5072-5259-b484-fac9a9f6f869...\n",
      "Error updating custom field for document 7293: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 7408 with R2R document ID 8673e6f3-641e-507e-ad41-83c2e32fc1bb...\n",
      "Error updating custom field for document 7408: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 8203 with R2R document ID 4f66665d-a078-59e1-adf2-b2e2f1c399b2...\n",
      "Error updating custom field for document 8203: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 7257 with R2R document ID 25219adf-53dd-533f-9c06-ab68c1cd919c...\n",
      "Error updating custom field for document 7257: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 8706 with R2R document ID 35b3fb0a-d158-59ad-a700-4645822d08d7...\n",
      "Error updating custom field for document 8706: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 7708 with R2R document ID 773790d7-6eea-5235-b1b9-35eddf1796c9...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-18 13:54:02,987 - INFO - pypaperless[paperless.escaffinity.com] - Closed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error updating custom field for document 7708: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 9173 with R2R document ID 3990327c-aad7-5a30-8cdf-6aba1a999ea3...\n",
      "Error updating custom field for document 9173: 'CustomFieldHelper' object has no attribute 'list'\n",
      "Updating Paperless document 7389 with R2R document ID e7e0f2c4-7164-5a9e-b20d-1c13e559f9e5...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Entry point\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 19\u001b[0m     \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/r2r/lib/python3.11/site-packages/nest_asyncio.py:30\u001b[0m, in \u001b[0;36m_patch_asyncio.<locals>.run\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     28\u001b[0m task \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(main)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task\u001b[38;5;241m.\u001b[39mdone():\n",
      "File \u001b[0;32m~/r2r/lib/python3.11/site-packages/nest_asyncio.py:92\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     90\u001b[0m     f\u001b[38;5;241m.\u001b[39m_log_destroy_pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping:\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/r2r/lib/python3.11/site-packages/nest_asyncio.py:115\u001b[0m, in \u001b[0;36m_patch_loop.<locals>._run_once\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m     heappop(scheduled)\n\u001b[1;32m    110\u001b[0m timeout \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ready \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mmax\u001b[39m(\n\u001b[1;32m    113\u001b[0m         scheduled[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_when \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime(), \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m86400\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m scheduled\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 115\u001b[0m event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_events(event_list)\n\u001b[1;32m    118\u001b[0m end_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clock_resolution\n",
      "File \u001b[0;32m/usr/lib/python3.11/selectors.py:468\u001b[0m, in \u001b[0;36mEpollSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    466\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 468\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_ev\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "#test program\n",
    "async def run():\n",
    "    paperless_url = \"https://paperless.escaffinity.com\"\n",
    "    paperless_api_key = \"0dad9947edf3a041e4e847160619213d908e3310\"\n",
    "    r2r_url = \"https://r2r.escaffinity.com\"\n",
    "    r2r_client = R2RClient(r2r_url)\n",
    "    paperless = Paperless(paperless_url, paperless_api_key)\n",
    "    await paperless.initialize()\n",
    "    try:\n",
    "        await backfill_r2r_ids_to_paperless(paperless, r2r_client, custom_field_name='document_id')\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing document: {e}\")\n",
    "    finally:\n",
    "        await paperless.close()\n",
    "\n",
    "nest_asyncio.apply()\n",
    "# Entry point\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(run())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def ensure_custom_field_exists(paperless, custom_field_name):\n",
    "    \"\"\"\n",
    "    Ensure that the custom field exists in Paperless. If it doesn't, create it.\n",
    "\n",
    "    :param paperless: Initialized Paperless client.\n",
    "    :param custom_field_name: The name of the custom field.\n",
    "    :return: The ID of the custom field.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Fetch existing custom fields\n",
    "        response = await paperless.get_custom_fields()\n",
    "        custom_fields = response.get(\"results\", [])\n",
    "\n",
    "        # Check if the custom field already exists\n",
    "        for field in custom_fields:\n",
    "            if field[\"name\"] == custom_field_name:\n",
    "                return field[\"id\"]\n",
    "\n",
    "        # If the custom field doesn't exist, create it\n",
    "        print(f\"Custom field '{custom_field_name}' does not exist. Creating it...\")\n",
    "        payload = {\n",
    "            \"name\": custom_field_name,\n",
    "            \"type\": \"string\"  # You may need to adjust this type based on your use case\n",
    "        }\n",
    "        created_field = await paperless.create_custom_field(payload)\n",
    "        return created_field[\"id\"]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error ensuring custom field '{custom_field_name}' exists: {e}\")\n",
    "        raise\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def update_custom_field(paperless, docid, custom_field_name, custom_field_value):\n",
    "    try:\n",
    "        # Fetch the document by docid\n",
    "        document = await paperless.documents(docid)\n",
    "        \n",
    "        # Update the custom fields list\n",
    "        document.custom_fields = [\n",
    "            {\n",
    "                \"value\": custom_field_value,\n",
    "                \"field\": custom_field_name\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # Save the changes\n",
    "        success = await document.update()\n",
    "        \n",
    "        if success:\n",
    "            print(f\"Successfully updated document {docid} with custom field {custom_field_name} = {custom_field_value}\")\n",
    "        else:\n",
    "            print(f\"Failed to update document {docid}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error updating custom field for document {docid}: {e}\")\n",
    "\n",
    "async def backfill_r2r_ids_to_paperless(paperless, r2r_client, custom_field_name='document_id'):\n",
    "    try:\n",
    "        print(\"Fetching all documents from R2R...\")\n",
    "        offset = 0\n",
    "        limit = 100  # Fetch documents in batches to avoid overwhelming the connection\n",
    "        has_more = True\n",
    "\n",
    "        while has_more:\n",
    "            # Fetch a batch of documents from R2R\n",
    "            response = r2r_client.documents.list(offset=offset, limit=limit)\n",
    "            r2r_documents = response.get(\"results\", [])\n",
    "            \n",
    "            if not r2r_documents:\n",
    "                print(\"No more documents found in R2R.\")\n",
    "                break\n",
    "\n",
    "            # Iterate through R2R documents and update Paperless\n",
    "            for r2r_doc in r2r_documents:\n",
    "                try:\n",
    "                    r2r_document_id = r2r_doc.get(\"id\")\n",
    "                    paperless_id = r2r_doc[\"metadata\"].get(\"PaperlessID\")\n",
    "                    \n",
    "                    if not paperless_id:\n",
    "                        print(f\"Skipping R2R document {r2r_document_id}: Missing 'PaperlessID' metadata.\")\n",
    "                        continue\n",
    "\n",
    "                    # Update the corresponding Paperless document using the existing update_custom_field function\n",
    "                    print(f\"Updating Paperless document {paperless_id} with R2R document ID {r2r_document_id}...\")\n",
    "                    await update_custom_field(paperless, paperless_id, custom_field_name, r2r_document_id)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error updating Paperless for R2R document {r2r_doc.get('id')}: {e}\")\n",
    "\n",
    "            # Update offset for the next batch\n",
    "            offset += limit\n",
    "            has_more = len(r2r_documents) == limit\n",
    "\n",
    "        print(\"Backfilling complete.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Critical error in backfill_r2r_ids_to_paperless: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-18 13:40:40,477 - INFO - pypaperless[paperless.escaffinity.com] - Initialized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching all documents from R2R...\n",
      "Updating Paperless document 866 with R2R document ID a2e17db8-5c07-521c-86f5-32a69374b814...\n",
      "Error updating custom field for document 866: Paperless [custom_fields -> field]: Incorrect type. Expected pk value, received str.\n",
      "Updating Paperless document 5344 with R2R document ID f9870517-2505-5c0e-9267-c2658a3a256f...\n",
      "Error updating custom field for document 5344: Paperless [custom_fields -> field]: Incorrect type. Expected pk value, received str.\n",
      "Updating Paperless document 5159 with R2R document ID 5df7ff9b-8e0c-5eaa-af63-4a56249eea99...\n",
      "Error updating custom field for document 5159: Paperless [custom_fields -> field]: Incorrect type. Expected pk value, received str.\n",
      "Updating Paperless document 7184 with R2R document ID 543d4ca3-374c-5a6e-8a2b-30677c987800...\n",
      "Error updating custom field for document 7184: Paperless [custom_fields -> field]: Incorrect type. Expected pk value, received str.\n",
      "Updating Paperless document 5469 with R2R document ID 25f576a9-b210-5e66-8b2a-620455834fc9...\n",
      "Error updating custom field for document 5469: Paperless [custom_fields -> field]: Incorrect type. Expected pk value, received str.\n",
      "Updating Paperless document 7228 with R2R document ID 9399702a-3039-5f77-8762-7d6093843d68...\n",
      "Error updating custom field for document 7228: Paperless [custom_fields -> field]: Incorrect type. Expected pk value, received str.\n",
      "Updating Paperless document 5432 with R2R document ID c832ba9f-8633-5a03-b3cf-2535e4143978...\n",
      "Error updating custom field for document 5432: Paperless [custom_fields -> field]: Incorrect type. Expected pk value, received str.\n",
      "Updating Paperless document 5475 with R2R document ID 90ff6a21-dd49-51c4-a970-3ea692aa435f...\n",
      "Error updating custom field for document 5475: Paperless [custom_fields -> field]: Incorrect type. Expected pk value, received str.\n",
      "Updating Paperless document 7670 with R2R document ID 35a4ffe4-0598-58df-9b3e-1dcc9b77d5c6...\n",
      "Error updating custom field for document 7670: Paperless [custom_fields -> field]: Incorrect type. Expected pk value, received str.\n",
      "Updating Paperless document 8946 with R2R document ID 4108fb08-66d8-51c7-9c79-87182402fef2...\n",
      "Error updating custom field for document 8946: Paperless [custom_fields -> field]: Incorrect type. Expected pk value, received str.\n",
      "Updating Paperless document 7284 with R2R document ID ebc2233a-a1ac-50e8-aff3-4fba21903cb1...\n",
      "Error updating custom field for document 7284: Paperless [custom_fields -> field]: Incorrect type. Expected pk value, received str.\n",
      "Updating Paperless document 3596 with R2R document ID 5e80b5e6-9301-5239-b81b-ac8edd4be185...\n",
      "Error updating custom field for document 3596: Paperless [custom_fields -> field]: Incorrect type. Expected pk value, received str.\n",
      "Updating Paperless document 8815 with R2R document ID a391a3a3-7e12-55f0-9594-23af999076ee...\n",
      "Error updating custom field for document 8815: Paperless [custom_fields -> field]: Incorrect type. Expected pk value, received str.\n",
      "Updating Paperless document 5426 with R2R document ID 810bf46a-93d1-530d-8eda-864de4cee75d...\n",
      "Error updating custom field for document 5426: Paperless [custom_fields -> field]: Incorrect type. Expected pk value, received str.\n",
      "Updating Paperless document 7347 with R2R document ID f8f6ba64-8ffc-5b19-9de1-2690d89efc0b...\n",
      "Error updating custom field for document 7347: Paperless [custom_fields -> field]: Incorrect type. Expected pk value, received str.\n",
      "Updating Paperless document 7753 with R2R document ID 319007f3-dd23-5a75-a02a-6310c5806c96...\n",
      "Error updating custom field for document 7753: Paperless [custom_fields -> field]: Incorrect type. Expected pk value, received str.\n",
      "Updating Paperless document 5522 with R2R document ID 825f2ee4-084e-5d21-b122-ff9b0e7d505c...\n",
      "Error updating custom field for document 5522: Paperless [custom_fields -> field]: Incorrect type. Expected pk value, received str.\n",
      "Updating Paperless document 5399 with R2R document ID cbb61301-3d8b-5c2d-b96d-df1e7fe1bdc5...\n",
      "Error updating custom field for document 5399: Paperless [custom_fields -> field]: Incorrect type. Expected pk value, received str.\n",
      "Updating Paperless document 7485 with R2R document ID 93e2b03d-6f6d-5ea2-a050-9b579623cf6b...\n",
      "Error updating custom field for document 7485: Paperless [custom_fields -> field]: Incorrect type. Expected pk value, received str.\n",
      "Updating Paperless document 7309 with R2R document ID 816e31b3-a255-5013-9e75-da473fc12f51...\n",
      "Error updating custom field for document 7309: Paperless [custom_fields -> field]: Incorrect type. Expected pk value, received str.\n",
      "Updating Paperless document 8609 with R2R document ID 0b26a20a-185d-548f-a007-cba971ed2958...\n",
      "Error updating custom field for document 8609: Paperless [custom_fields -> field]: Incorrect type. Expected pk value, received str.\n",
      "Updating Paperless document 7586 with R2R document ID 7eb4e3f1-e4ec-5228-bc4d-b04a4547aceb...\n",
      "Error updating custom field for document 7586: Paperless [custom_fields -> field]: Incorrect type. Expected pk value, received str.\n",
      "Updating Paperless document 7312 with R2R document ID 1082b2fe-380e-5e1f-bb11-655e8a4ea301...\n",
      "Error updating custom field for document 7312: Paperless [custom_fields -> field]: Incorrect type. Expected pk value, received str.\n",
      "Updating Paperless document 5265 with R2R document ID adc274a4-6456-52cc-97ef-94bfbe4df249...\n",
      "Error updating custom field for document 5265: Paperless [custom_fields -> field]: Incorrect type. Expected pk value, received str.\n",
      "Updating Paperless document 7405 with R2R document ID 0ae0e44d-c892-5765-945e-e1b494e6bbab...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-18 13:40:44,338 - INFO - pypaperless[paperless.escaffinity.com] - Closed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error updating custom field for document 7405: Paperless [custom_fields -> field]: Incorrect type. Expected pk value, received str.\n",
      "Updating Paperless document 7424 with R2R document ID feb8e987-4de6-5730-a420-4d43dd1f59b6...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Entry point\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 18\u001b[0m     \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/r2r/lib/python3.11/site-packages/nest_asyncio.py:30\u001b[0m, in \u001b[0;36m_patch_asyncio.<locals>.run\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     28\u001b[0m task \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(main)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task\u001b[38;5;241m.\u001b[39mdone():\n",
      "File \u001b[0;32m~/r2r/lib/python3.11/site-packages/nest_asyncio.py:92\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     90\u001b[0m     f\u001b[38;5;241m.\u001b[39m_log_destroy_pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping:\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/r2r/lib/python3.11/site-packages/nest_asyncio.py:115\u001b[0m, in \u001b[0;36m_patch_loop.<locals>._run_once\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m     heappop(scheduled)\n\u001b[1;32m    110\u001b[0m timeout \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ready \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mmax\u001b[39m(\n\u001b[1;32m    113\u001b[0m         scheduled[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_when \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime(), \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m86400\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m scheduled\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 115\u001b[0m event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_events(event_list)\n\u001b[1;32m    118\u001b[0m end_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clock_resolution\n",
      "File \u001b[0;32m/usr/lib/python3.11/selectors.py:468\u001b[0m, in \u001b[0;36mEpollSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    466\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 468\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selector\u001b[38;5;241m.\u001b[39mpoll(timeout, max_ev)\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "async def run():\n",
    "    paperless_url = \"https://paperless.escaffinity.com\"\n",
    "    paperless_api_key = \"0dad9947edf3a041e4e847160619213d908e3310\"\n",
    "    r2r_url = \"https://r2r.escaffinity.com\"\n",
    "    r2r_client = R2RClient(r2r_url)\n",
    "    paperless = Paperless(paperless_url, paperless_api_key)\n",
    "    await paperless.initialize()\n",
    "    try:\n",
    "        await backfill_r2r_ids_to_paperless(paperless, r2r_client, custom_field_name='document_id')\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing document: {e}\")\n",
    "    finally:\n",
    "        await paperless.close()\n",
    "\n",
    "nest_asyncio.apply()\n",
    "# Entry point\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(run())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-18 13:29:20,731 - INFO - pypaperless[paperless.escaffinity.com] - Initialized.\n",
      "2024-12-18 13:29:20,958 - INFO - pypaperless[paperless.escaffinity.com] - Closed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CustomFieldValueType(field=3, value='f9870517-2505-5c0e-9267-c2658a3a256f')]\n"
     ]
    }
   ],
   "source": [
    "#testing getting custom_fields\n",
    "async def run():\n",
    "    paperless_url = \"https://paperless.escaffinity.com\"\n",
    "    paperless_api_key = \"0dad9947edf3a041e4e847160619213d908e3310\"\n",
    "    r2r_url = \"https://r2r.escaffinity.com\"\n",
    "    r2r_client = R2RClient(r2r_url)\n",
    "    paperless = Paperless(paperless_url, paperless_api_key)\n",
    "    document_id = \"f9870517-2505-5c0e-9267-c2658a3a256f\"\n",
    "    await paperless.initialize()\n",
    "    try:\n",
    "        document = await paperless.documents(5344)\n",
    "        custom_fields = document.custom_fields\n",
    "        print(custom_fields)\n",
    "        document.custom_fields = [\n",
    "        {\n",
    "            \"value\": document_id,\n",
    "            \"field\": 3\n",
    "        }]\n",
    "        success = await document.update()\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing document: {e}\")\n",
    "    finally:\n",
    "        await paperless.close()\n",
    "\n",
    "nest_asyncio.apply()\n",
    "# Entry point\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(run())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
